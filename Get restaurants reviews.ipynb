{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "644fa368",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\elena\\anaconda3\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\elena\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\elena\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\elena\\anaconda3\\lib\\site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\elena\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\elena\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: idna in c:\\users\\elena\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\elena\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\elena\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\elena\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\elena\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\elena\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\elena\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\elena\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\elena\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\elena\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\elena\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: webdriver-manager in c:\\users\\elena\\anaconda3\\lib\\site-packages (3.8.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\elena\\anaconda3\\lib\\site-packages (from webdriver-manager) (21.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\elena\\anaconda3\\lib\\site-packages (from webdriver-manager) (4.64.0)\n",
      "Requirement already satisfied: requests in c:\\users\\elena\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.27.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\elena\\anaconda3\\lib\\site-packages (from webdriver-manager) (1.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\elena\\anaconda3\\lib\\site-packages (from packaging->webdriver-manager) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\elena\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\elena\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\elena\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\elena\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2021.10.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\elena\\anaconda3\\lib\\site-packages (from tqdm->webdriver-manager) (0.4.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\elena\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\elena\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\elena\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\elena\\anaconda3\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\elena\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# install the necessary extra libraries to run the script\n",
    "#!apt-get update\n",
    "#!apt-get install chromium chromium-driver\n",
    "!pip install selenium\n",
    "!pip install webdriver-manager\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f7acb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import selenium, BeautifulSoup and other libraries to run the script\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from pandas import DataFrame\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from IPython.display import Image, display, clear_output\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import undetected_chromedriver as uc\n",
    "import urllib.request\n",
    "\n",
    "# define constants to define the maximum waiting time and maximum amount of reviews to collect\n",
    "MAX_WAIT = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "582533d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to take a screenshot of the headless browser and display it\n",
    "def take_screenshot(driver):\n",
    "    driver.save_screenshot(\"scraping_folder/pageImage.png\")\n",
    "    display(Image(filename=\"scraping_folder/pageImage.png\"))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79fa55e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to take a screenshot of the headless browser and display it, then clean the outcome after a few seconds\n",
    "def take_screenshot_and_clear(driver):\n",
    "    driver.save_screenshot(\"scraping_folder/pageImage.png\")\n",
    "    display(Image(filename=\"scraping_folder/pageImage.png\"))\n",
    "    \n",
    "    time.sleep(3)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cb0f6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to move to the next page\n",
    "def next_page(driver):   \n",
    "    exists=1\n",
    "    #check for the presence of privacy banner\n",
    "    try:\n",
    "        if driver.find_element(By.ID,'onetrust-accept-btn-handler') is not None:\n",
    "            wait.until(EC.element_to_be_clickable((By.ID,'onetrust-accept-btn-handler'))).click()\n",
    "    except Exception as e:\n",
    "        print()\n",
    "    #go to the next page  \n",
    "    try:\n",
    "        #get next button\n",
    "        button=driver.find_element(By.CSS_SELECTOR, '.nav.next.ui_button.primary')\n",
    "        if button.get_property('disabled')!=0:\n",
    "            # wait until the next page button is clickable and then click it\n",
    "            WebDriverWait(driver, MAX_WAIT).until(EC.element_to_be_clickable((By.CSS_SELECTOR, '.nav.next.ui_button.primary'))).click()\n",
    "        else:\n",
    "            exists=0\n",
    "    except Exception as e:\n",
    "        exists=0\n",
    "        print()\n",
    "\n",
    "    return exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51df2520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to\n",
    "def expand_review(driver):\n",
    "    # define an element to wait for an event to happen\n",
    "    ex_wait = WebDriverWait(driver, MAX_WAIT)\n",
    "\n",
    "    # load the complete review text in the HTML\n",
    "    try:\n",
    "        # wait until the element is clickable and when it is clickable, click it\n",
    "        ex_wait.until(EC.element_to_be_clickable(\n",
    "                    (By.XPATH,'//*[@id=\"taplc_location_reviews_list_resp_rr_resp_0\"]/div/div[11]'))\n",
    "                  ).click()\n",
    "\n",
    "        # wait complete reviews to load\n",
    "        time.sleep(5)\n",
    "    # raised if there is no link for expansion (e.g.: set of short reviews)\n",
    "    # IMPORTANT: nothing will be printed to avoid dirty outputs\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfd0ff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_reviews(driver):\n",
    "    #check for the presence of privacy banner\n",
    "    try:\n",
    "        if driver.find_element(By.ID,'onetrust-accept-btn-handler') is not None:\n",
    "            wait.until(EC.element_to_be_clickable((By.ID,'onetrust-accept-btn-handler'))).click()\n",
    "    except Exception as e:\n",
    "        print()\n",
    "    #click on \"More\"\n",
    "    try:\n",
    "        plus_button=driver.find_element(By.CSS_SELECTOR, '.taLnk.ulBlueLinks')\n",
    "        ActionChains(driver).move_to_element(plus_button).click().perform()\n",
    "        #wait complete reviews to load\n",
    "        time.sleep(3)\n",
    "    except Exception as e:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c413755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review_data(resp, n_reviews, collected_data):\n",
    "    take_screenshot(driver)\n",
    "    \n",
    "    # get the place's name\n",
    "    name = resp.find('h1', class_ = 'HjBfq').text\n",
    "    print(name)\n",
    "            \n",
    "    # collect the reviews\n",
    "    r_list = resp.find_all('div', class_= 'reviewSelector')\n",
    "    \n",
    "    # for each review\n",
    "    for idx, review in enumerate(r_list):\n",
    "        #get id review\n",
    "        id_review= review.get(\"data-reviewid\")\n",
    "        print(id_review)\n",
    "        # get review date\n",
    "        if review.find('div', class_='ui_column is-9') is not None:\n",
    "            # the field may contain other textual contents, hence we only take the first 8 characters\n",
    "            review_date = review.find('div', class_='ui_column is-9').find('span', class_='ratingDate').text\n",
    "        else:\n",
    "            # some reviews may have no date\n",
    "            review_date = None\n",
    "\n",
    "        print(review_date)\n",
    "        #get user id\n",
    "        user_id=None\n",
    "        if review.find('div', class_='memberOverlayLink clickable') is not None:\n",
    "            user_id=review.find('div', class_='memberOverlayLink clickable').get(\"id\").split('-')[0]\n",
    "        print(user_id)\n",
    "        \n",
    "        userLoc=None\n",
    "        # get reviewer information: username, location\n",
    "        if review.find('div', class_='info_text pointer_cursor') is not None:\n",
    "            username=review.find('div', class_='info_text pointer_cursor').text\n",
    "            if review.find('div', class_='info_text pointer_cursor').find(\"div\", class_='userLoc') is not None:\n",
    "                userLoc=review.find('div', class_='info_text pointer_cursor').find(\"div\", class_='userLoc').text\n",
    "                username=username.removesuffix(userLoc) \n",
    "        else:\n",
    "            username='anonima'\n",
    "        print(username)\n",
    "        print(userLoc)\n",
    "        #get number of reviews made by the user\n",
    "        num_of_user_review=None\n",
    "        if review.find('div', class_='reviewerBadge badge') is not None:\n",
    "            if review.find('div', class_='reviewerBadge badge').find(\"span\", class_='badgeText') is not None:\n",
    "                num_of_user_review=review.find('div', class_='reviewerBadge badge').find(\"span\", class_='badgeText').text\n",
    "        elif review.find('div', class_='memberBadgingNoText is-shown-at-tablet') is not None:\n",
    "            if review.find('div', class_='memberBadgingNoText is-shown-at-tablet').find(\"span\", class_='badgetext') is not None:\n",
    "                num_of_user_review=review.find('div', class_='memberBadgingNoText is-shown-at-tablet').find(\"span\", class_='badgetext').text\n",
    "        print(num_of_user_review)\n",
    "        \n",
    "        # get rating of review by looking at the aria-label of the svg with the dots       \n",
    "        rating_review = review.find('div', class_='ui_column is-9').find(\"span\", class_='ui_bubble_rating')\n",
    "        rating_review=float(rating_review.get(\"class\")[1].split('_')[1])\n",
    "        rating_review=str(rating_review/10).replace(',', '.')\n",
    "        print(rating_review)\n",
    "\n",
    "        # get review title\n",
    "        title = review.find('div', class_='quote').find('a', class_='title').text\n",
    "        print(title)\n",
    "        \n",
    "        # get review complete text\n",
    "        if review.find('div', class_='entry') is not None:                \n",
    "            caption=review.find('div', class_='entry').text\n",
    "            caption=caption.replace('Mostra meno','')\n",
    "        print(caption)\n",
    "        \n",
    "        #get visit date\n",
    "        if review.find('div', class_='prw_rup prw_reviews_stay_date_hsx') is not None:\n",
    "            visit_date=review.find('div', class_='prw_rup prw_reviews_stay_date_hsx').text\n",
    "        else:\n",
    "            visit_date=None\n",
    "\n",
    "        print(visit_date)\n",
    "        \n",
    "        quality_rating=None \n",
    "        atmosphere_rating=None \n",
    "        service_rating=None \n",
    "        food_rating=None \n",
    "        aspect_rated=0\n",
    "        #get aspect ratings\n",
    "        if review.find('div', class_='rating-list') is not None:\n",
    "            if review.find('div', class_='rating-list').find('div', class_='recommend-description') is not None:\n",
    "                elements=review.find('div', class_='rating-list').find_all('div', class_='recommend-description')\n",
    "                bubble_ratings=review.find('div', class_='rating-list').find_all('div', class_='ui_bubble_rating')\n",
    "                for elem in elements:\n",
    "                    if elem.text=='Qualit√†/prezzo':\n",
    "                        quality_rating=float(bubble_ratings[aspect_rated].get(\"class\")[1].split('_')[1])\n",
    "                        quality_rating=str(quality_rating/10).replace(',', '.')\n",
    "                        aspect_rated+=1\n",
    "                    elif elem.text=='Atmosfera':\n",
    "                        atmosphere_rating=float(bubble_ratings[aspect_rated].get(\"class\")[1].split('_')[1])\n",
    "                        atmosphere_rating=str(atmosphere_rating/10).replace(',', '.')\n",
    "                        aspect_rated+=1\n",
    "                    elif elem.text=='Servizio':\n",
    "                        service_rating=float(bubble_ratings[aspect_rated].get(\"class\")[1].split('_')[1])\n",
    "                        service_rating=str(service_rating/10).replace(',', '.')\n",
    "                        aspect_rated+=1\n",
    "                    else:\n",
    "                        food_rating=float(bubble_ratings[aspect_rated].get(\"class\")[1].split('_')[1])\n",
    "                        food_rating=str(food_rating/10).replace(',', '.')\n",
    "        \n",
    "        print(quality_rating)  \n",
    "        print(atmosphere_rating)\n",
    "        print(service_rating)\n",
    "        print(food_rating)\n",
    "        \n",
    "        # build review item\n",
    "        item = {\n",
    "            'id_review': id_review, # real id_review\n",
    "            'name': name,\n",
    "            'user_id': user_id,\n",
    "            'userLoc': userLoc,\n",
    "            'title': title,\n",
    "            'caption': caption,\n",
    "            'date': review_date,\n",
    "            'rating': rating_review,\n",
    "            'username': username,\n",
    "            'visit_date': visit_date,\n",
    "            'quality_rating': quality_rating,\n",
    "            'atmosphere_rating': atmosphere_rating,\n",
    "            'service_rating': service_rating,\n",
    "            'food_rating': food_rating,\n",
    "            'num_of_user_review': num_of_user_review\n",
    "         }\n",
    "\n",
    "         # count the number of reviews collected\n",
    "        n_reviews = n_reviews + 1\n",
    "        \n",
    "        # add the item to the array of reviews collected\n",
    "        collected_data.append(item)       \n",
    "\n",
    "    time.sleep(5)\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # return the review count and the data collected\n",
    "    return n_reviews, collected_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83cafe04",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "if done\n"
     ]
    }
   ],
   "source": [
    "# kill the chrome process to ensure a fresh start\n",
    "!pkill chrome\n",
    "\n",
    "# define the options to run Chrome\n",
    "# IMPORTANT: these options are quite essential, especially when running it in a remote environment like Google Colab\n",
    "options = webdriver.ChromeOptions()\n",
    "# define the size of the window\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "# disable notifications to avoid useless interactions \n",
    "options.add_argument(\"--disable-notifications\")\n",
    "# disable the developer options\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "# set the browser to be headless (i.e., the browser window will be hidden)\n",
    "options.add_argument('--headless')\n",
    "# set the browser to run all scripts\n",
    "options.add_argument('--no-sandbox')\n",
    "\n",
    "service = Service(executable_path=\"./chromedriver.exe\")\n",
    "#service = Service()\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "#driver = webdriver.Chrome(service=Service(ChromeDriverManager(version='114.0.5735.90').install()),options=options)\n",
    "#driver = webdriver.Chrome(ChromeDriverManager(version='114.0.5735.90').install(),options=options)\n",
    "#driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# define an element to wait until an event occurs\n",
    "wait = WebDriverWait(driver, MAX_WAIT)\n",
    "\n",
    "#load urls file\n",
    "file_url=pd.read_csv('Firenze/Firenze collected review.CSV', sep=';')\n",
    "#file_url=pd.DataFrame(pd.read_csv('Firenze/Firenze collected review.CSV'), columns=['Urls', 'Number of Ratings', 'Details'])\n",
    "num_of_urls=len(file_url)\n",
    "\n",
    "for index in range(0, num_of_urls):\n",
    "    #if the url has not yet been inspected\n",
    "    if(file_url.loc[index,'Details']==0):\n",
    "        #retrieve url\n",
    "        url=file_url.loc[index,'Urls']\n",
    "        # get the page with Selenium\n",
    "        driver.get(url)\n",
    "        \n",
    "        # scroll and move to the filter section\n",
    "        driver.execute_script('window.scrollBy(0,2500)')\n",
    "        \n",
    "        # expand the list of reviews (if needed)\n",
    "        expand_review(driver)\n",
    "    \n",
    "        take_screenshot(driver)\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        # wait for the page to be loaded\n",
    "        WebDriverWait(driver, MAX_WAIT).until(EC.visibility_of_element_located((By.CSS_SELECTOR, '.memberOverlayLink.clickable')))\n",
    "        \n",
    "        #expand reviews\n",
    "        open_reviews(driver)\n",
    "        # send the page manipulated with Selenium to BeautifulSoup parser\n",
    "        response = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        n_reviews=0\n",
    "        collected_data=[]\n",
    "         \n",
    "        name = response.find('h1', class_ = 'HjBfq').text\n",
    "        pathname = name.replace('?','')\n",
    "        pathname = pathname.replace('\"','')\n",
    "        pathname = pathname.replace('!...','')\n",
    "        pathname = pathname.replace(':','')\n",
    "        pathname = pathname.replace('/','')\n",
    "        pathname = pathname.rstrip()\n",
    "        #get the number of scraped reviews and the data collected\n",
    "        n_reviews, collected_data = get_review_data(response, n_reviews, collected_data)\n",
    "           \n",
    "        while True:\n",
    "            # move to the next page\n",
    "            exists=next_page(driver) \n",
    "            if exists==0:\n",
    "                print(\"if done\")\n",
    "                break\n",
    "            # if there are still review pages\n",
    "            # repeat the same process as before\n",
    "            driver.execute_script('window.scrollBy(0,2500)')            \n",
    "            \n",
    "            expand_review(driver)\n",
    "\n",
    "            WebDriverWait(driver, MAX_WAIT).until(EC.visibility_of_element_located((By.CSS_SELECTOR, '.memberOverlayLink.clickable')))              \n",
    "            \n",
    "            open_reviews(driver)\n",
    "            response = BeautifulSoup(driver.page_source, 'html.parser') \n",
    "            \n",
    "            n_reviews, collected_data = get_review_data(response, n_reviews, collected_data)\n",
    "        #save reviews              \n",
    "        df = DataFrame({'collected_data': collected_data})\n",
    "        out_path = 'Firenze\\\\'+pathname+\"\\\\\"+pathname+\" reviews.xlsx\"\n",
    "        writer = pd.ExcelWriter(out_path , engine='xlsxwriter')\n",
    "        df.to_excel(writer, sheet_name='sheet1')\n",
    "        writer.save()\n",
    "        #define the url as seen\n",
    "        file_url.loc[index, 'Details'] = 1\n",
    "        file_url.to_csv(\"Firenze/Firenze collected review.CSV\", index=False)\n",
    "        time.sleep(2)\n",
    "        clear_output(wait=True)\n",
    "\n",
    "# close the driver\n",
    "driver.close()\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc514fed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
